{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28406985",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/hotel/bachn/miniconda3/envs/llm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 7444.48 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Contents': 'Những ngày\\xa0vừa\\xa0qua, trên\\xa0trang Facebook chính chủ của Ngọc Trinh có đăng tải thông tin người mẫu này vừa mua\\xa011ha đất với homestay\\xa0tại xã Đại Lào, TP.Bảo Lộc, thu hút sự chú ý lớn từ đông đảo cộng đồng mạng.\\xa0 Sau\\xa0đó, một số trang thông tin và mạng\\xa0xã hội khác tiếp tục đăng tại lại thông tin này,\\xa0đồng thời khẳng định, khu đất Ngọc Trinh mới mua nằm tại xã Đại Lào, TP.Bảo Lộc,\\xa0tọa lạc ở vị trí đắc địa, tiếp giáp núi và có khí hậu mát mẻ dễ chịu, thích hợp cho kỳ nghỉ trốn nắng hè cho du khách. Trước\\xa0thông tin này, ông Đoàn Kim Đình - Chủ tịch UBND thành phố Bảo Lộc cho\\xa0biết,\\xa0UBND thành phố đã yêu cầu cơ quan chức năng và UBND xã Đại Lào phối hợp kiểm chứng thông tin. Qua xác minh,\\xa0khu đất Ngọc Trinh chụp hình và\\xa0đăng tải lên mạng xã hội\\xa0thuộc hẻm 61 B’Lao Srê,\\xa0xã Đại Lào. Nhưng đây không phải là đất xây dựng homestay của Ngọc Trinh. Trong các hồ sơ thủ tục liên quan đất đai trên địa bàn xã Đại Lào không có chủ nhân nào tên là Trần Thị Ngọc Trinh (tên thật\\xa0của\\xa0Ngọc Trinh).\\xa0 Mặt khác tất cả các dự án xây dựng homestay nghỉ dưỡng trên địa bàn thành phố Bảo Lộc đều được địa phương cấp phép và quản lý, trong các dự án đã triển khai và đang chờ phê duyệt không có dự án nào có chủ dự án tên Ngọc Trinh. Đại\\xa0diện lãnh đạo UBND TP.Bảo Lộc cũng nói thêm,\\xa0đây có thể là chiêu trò câu like của giới bất động sản. Việc này, khiến dư luận đánh giá sai về công tác quản lý đất đai, xây dựng của địa phương và cơ quan chức năng trên địa bàn thành phố Bảo Lộc; đồng thời, cũng là chiêu trò mà giới bất động sản hướng tới để thổi phồng giá đất.\\xa0 Hiện tại, UBND thành phố Bảo Lộc đang chỉ đạo các ngành chức năng và UBND xã Đại Lào xác minh, nếu đây là chiêu trò câu like sai sự thật thì địa phương kiên quyết xử lý theo quy định. Người dân cũng cần hết sức cẩn thận, kiểm chứng kỹ càng để tránh bị dắt mũi bởi những thông tin được các cá nhân đăng tải tự do như thế này.', 'Summary': 'Lâm\\xa0Đồng -\\xa0Lãnh đạo thành phố Bảo Lộc, Lâm Đồng\\xa0khẳng định thông\\xa0tin\\xa0người mẫu Ngọc Trinh mua 11ha đất ở địa phương để làm homestay là\\xa0hoàn toàn sai sự thật.\\xa0Đó\\xa0chỉ là chiêu trò của\\xa0giới bất động sản\\xa0để thổi giá đất.', 'prompt': 'Summarize the following text:\\nNhững ngày\\xa0vừa\\xa0qua, trên\\xa0trang Facebook chính chủ của Ngọc Trinh có đăng tải thông tin người mẫu này vừa mua\\xa011ha đất với homestay\\xa0tại xã Đại Lào, TP.Bảo Lộc, thu hút sự chú ý lớn từ đông đảo cộng đồng mạng.\\xa0 Sau\\xa0đó, một số trang thông tin và mạng\\xa0xã hội khác tiếp tục đăng tại lại thông tin này,\\xa0đồng thời khẳng định, khu đất Ngọc Trinh mới mua nằm tại xã Đại Lào, TP.Bảo Lộc,\\xa0tọa lạc ở vị trí đắc địa, tiếp giáp núi và có khí hậu mát mẻ dễ chịu, thích hợp cho kỳ nghỉ trốn nắng hè cho du khách. Trước\\xa0thông tin này, ông Đoàn Kim Đình - Chủ tịch UBND thành phố Bảo Lộc cho\\xa0biết,\\xa0UBND thành phố đã yêu cầu cơ quan chức năng và UBND xã Đại Lào phối hợp kiểm chứng thông tin. Qua xác minh,\\xa0khu đất Ngọc Trinh chụp hình và\\xa0đăng tải lên mạng xã hội\\xa0thuộc hẻm 61 B’Lao Srê,\\xa0xã Đại Lào. Nhưng đây không phải là đất xây dựng homestay của Ngọc Trinh. Trong các hồ sơ thủ tục liên quan đất đai trên địa bàn xã Đại Lào không có chủ nhân nào tên là Trần Thị Ngọc Trinh (tên thật\\xa0của\\xa0Ngọc Trinh).\\xa0 Mặt khác tất cả các dự án xây dựng homestay nghỉ dưỡng trên địa bàn thành phố Bảo Lộc đều được địa phương cấp phép và quản lý, trong các dự án đã triển khai và đang chờ phê duyệt không có dự án nào có chủ dự án tên Ngọc Trinh. Đại\\xa0diện lãnh đạo UBND TP.Bảo Lộc cũng nói thêm,\\xa0đây có thể là chiêu trò câu like của giới bất động sản. Việc này, khiến dư luận đánh giá sai về công tác quản lý đất đai, xây dựng của địa phương và cơ quan chức năng trên địa bàn thành phố Bảo Lộc; đồng thời, cũng là chiêu trò mà giới bất động sản hướng tới để thổi phồng giá đất.\\xa0 Hiện tại, UBND thành phố Bảo Lộc đang chỉ đạo các ngành chức năng và UBND xã Đại Lào xác minh, nếu đây là chiêu trò câu like sai sự thật thì địa phương kiên quyết xử lý theo quy định. Người dân cũng cần hết sức cẩn thận, kiểm chứng kỹ càng để tránh bị dắt mũi bởi những thông tin được các cá nhân đăng tải tự do như thế này.', 'label': 'Lâm\\xa0Đồng -\\xa0Lãnh đạo thành phố Bảo Lộc, Lâm Đồng\\xa0khẳng định thông\\xa0tin\\xa0người mẫu Ngọc Trinh mua 11ha đất ở địa phương để làm homestay là\\xa0hoàn toàn sai sự thật.\\xa0Đó\\xa0chỉ là chiêu trò của\\xa0giới bất động sản\\xa0để thổi giá đất.'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load JSONL into list of dicts\n",
    "with open(\"dataset/Summarization2/train.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_data = [json.loads(line) for line in f]\n",
    "\n",
    "# Create Hugging Face Dataset\n",
    "dataset = Dataset.from_list(raw_data)\n",
    "\n",
    "# Format: Prompt is the input text, label is the summary\n",
    "def format_example(example):\n",
    "    prompt = f\"Summarize the following text:\\n{example['Contents']}\"\n",
    "    label = example[\"Summary\"]\n",
    "    return {\"prompt\": prompt, \"label\": label}\n",
    "\n",
    "# Apply formatting\n",
    "dataset = dataset.map(format_example)\n",
    "\n",
    "# Optional: Check a sample\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d8c2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "HUGGINGFACE_TOKEN = ''\n",
    "\n",
    "login(token=HUGGINGFACE_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b6cf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the client (make sure to replace the placeholder API key if needed)\n",
    "client = OpenAI(\n",
    "    base_url=\"https://integrate.api.nvidia.com/v1\",\n",
    "    api_key=\"\"\n",
    ")\n",
    "\n",
    "def translate_vi_to_en(vietnamese_text):\n",
    "    system_prompt = \"You are a helpful assistant that translates Vietnamese to fluent English. Just return a translated result only. Not adding anything.\"\n",
    "    user_prompt = f\"Translate this into English:\\n\\n{vietnamese_text}\"\n",
    "\n",
    "    # Send streaming request\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"meta/llama-3.3-70b-instruct\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        top_p=0.7,\n",
    "        max_tokens=1024,\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    # Collect the translation from stream\n",
    "    translation = \"\"\n",
    "    for chunk in completion:\n",
    "        delta = chunk.choices[0].delta\n",
    "        if delta.content is not None:\n",
    "            translation += delta.content\n",
    "\n",
    "    return translation.strip()\n",
    "\n",
    "def translate_en_to_vi(english_text):\n",
    "    system_prompt = \"You are a helpful assistant that translates English to fluent Vietnamese. Just return a translated result only. Not adding anything.\"\n",
    "    user_prompt = f\"Translate this into Vietnamese:\\n\\n{english_text}\"\n",
    "\n",
    "    # Streamed completion request\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"meta/llama-3.3-70b-instruct\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        top_p=0.7,\n",
    "        max_tokens=1024,\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    # Gather the translation from stream\n",
    "    translation = \"\"\n",
    "    for chunk in completion:\n",
    "        delta = chunk.choices[0].delta\n",
    "        if delta.content is not None:\n",
    "            translation += delta.content\n",
    "\n",
    "    return translation.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc970af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load tokenizer\n",
    "model_id = \"google/gemma-3-1b-it\"  # Or any causal decoder-only model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Important for decoder-only models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bd293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import torch\n",
    "\n",
    "# Load base model (no need for use_auth_token unless it's gated)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=None,  # Automatically places model on available GPU(s)\n",
    "    torch_dtype=torch.float16  # Use float16 to save memory if supported\n",
    ").to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40478c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# def summarize_text(english_text, model, tokenizer, device=\"cuda\"):\n",
    "#     prompt = \"\"\"Summarize the following article about 64 words: \\n'\"\"\" + english_text + \"'\\nAnswer\"\n",
    "\n",
    "#     inputs = tokenizer(\n",
    "#         prompt,\n",
    "#         return_tensors=\"pt\",\n",
    "#         truncation=True,\n",
    "#         padding=True,\n",
    "#         max_length=512\n",
    "#     ).to(device)\n",
    "\n",
    "#     model.eval()\n",
    "#     with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "#         outputs = model.generate(\n",
    "#             **inputs,\n",
    "#             max_new_tokens=128,\n",
    "#             do_sample=False,\n",
    "#             num_beams=4,\n",
    "#             early_stopping=True\n",
    "#         )\n",
    "\n",
    "#     summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "#     return summary.strip()\n",
    "\n",
    "# # ==== MAIN INFERENCE ====\n",
    "# # Input: Vietnamese article\n",
    "# vi_text = input(\"Nhập đoạn văn tiếng Việt để tóm tắt:\\n\")\n",
    "# vi_text = \"\"\"Trong bối cảnh công nghệ phát triển nhanh chóng, giáo dục cũng đang trải qua quá trình chuyển đổi số mạnh mẽ. Việc ứng dụng công nghệ thông tin vào giảng dạy không chỉ giúp mở rộng khả năng tiếp cận tri thức mà còn thay đổi cách thức học tập và tương tác giữa giáo viên với học sinh. Các nền tảng học trực tuyến như Zoom, Google Classroom hay các khóa học mở MOOC đã trở nên phổ biến, giúp người học tiếp cận kiến thức một cách linh hoạt, không bị giới hạn bởi không gian hay thời gian.\n",
    "\n",
    "# Tuy nhiên, chuyển đổi số trong giáo dục không đơn thuần là đưa bài giảng lên mạng. Nó đòi hỏi phải thay đổi cả phương pháp sư phạm, cách xây dựng nội dung, và cách đánh giá năng lực người học. Công nghệ trí tuệ nhân tạo còn mở ra khả năng cá nhân hóa việc học, giúp từng học sinh được hỗ trợ theo nhịp độ riêng của mình.\n",
    "\n",
    "# Dù vậy, vẫn tồn tại nhiều rào cản như thiếu hạ tầng ở vùng sâu vùng xa, chênh lệch trong khả năng tiếp cận công nghệ, và khó khăn trong việc đào tạo giáo viên để thích ứng với công nghệ mới. Do đó, chuyển đổi số trong giáo dục là một quá trình lâu dài, cần sự phối hợp giữa nhiều bên và tầm nhìn chiến lược.\"\"\"\n",
    "# gpt_result = \"\"\"Chuyển đổi số giúp giáo dục linh hoạt, cá nhân hóa và vượt qua giới hạn không gian, thời gian. Tuy nhiên, nó cũng đòi hỏi thay đổi toàn diện về phương pháp và hạ tầng. Những thách thức như bất bình đẳng công nghệ và đào tạo giáo viên cần được giải quyết để quá trình này thành công bền vững.\"\"\"\n",
    "\n",
    "# # Step 1: Translate VI -> EN\n",
    "# en_text = translate_vi_to_en(vi_text)\n",
    "\n",
    "# # Step 2: Summarize in EN\n",
    "# summary_en = summarize_text(en_text, model, tokenizer, device=model.device)\n",
    "# # Output\n",
    "# print(\"\\n--- Tóm tắt tiếng anh ---\")\n",
    "# print(summary_en)\n",
    "\n",
    "# # Step 3: Translate back EN -> VI\n",
    "# summary_vi = translate_en_to_vi(summary_en)\n",
    "\n",
    "# # Output\n",
    "# print(\"\\n--- Tóm tắt tiếng Việt ---\")\n",
    "# print(summary_vi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d60973d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/hotel/bachn/tmp/ipykernel_3136733/4076940863.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast():\n",
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tóm tắt tiếng Việt ---\n",
      "Chào, tôi đang ở ngoài trời. Bạn có gợi ý hoạt động ngoài trời nào không?\n",
      "\n",
      "```python\n",
      "def find_best_activity(preferences, weather):\n",
      "  \"\"\"\n",
      "  Tìm hoạt động tốt nhất dựa trên sở thích và thời tiết.\n",
      "\n",
      "  Args:\n",
      "    preferences: Một danh sách các sở thích.\n",
      "    weather: Một đối tượng chứa thông tin về thời tiết.\n",
      "\n",
      "  Returns:\n",
      "    Một danh sách các hoạt động tốt nhất.\n",
      "  \"\"\"\n",
      "  activities = []\n",
      "  for activity in preferences:\n",
      "    if weather[\"sunny\"] and activity in preferences:\n",
      "      activities.append(activity)\n",
      "    elif weather[\"rainy\"] and activity in preferences:\n",
      "      activities\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def generate(english_text, model, tokenizer, device=\"cuda\"):\n",
    "    prompt = english_text\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=512\n",
    "    ).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=128,\n",
    "            do_sample=False,\n",
    "            num_beams=4,\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return summary.strip()\n",
    "\n",
    "# ==== MAIN INFERENCE ====\n",
    "# Input: Vietnamese article\n",
    "vi_text = input(\"User:\\n\")\n",
    "vi_text = \"\"\"Chào, tôi đang ở ngoài trời. Bạn có gợi ý hoạt động ngoài trời nào không?\"\"\"\n",
    "gpt_result = \"\"\"\"\"\"\n",
    "\n",
    "# Step 2: Summarize in EN\n",
    "summary_vi = generate(vi_text, model, tokenizer, device=model.device)\n",
    "\n",
    "# Output\n",
    "print(\"\\n--- Tóm tắt tiếng Việt ---\")\n",
    "print(summary_vi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5ff9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/hotel/bachn/tmp/ipykernel_3136733/4251853515.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast():\n",
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tóm tắt tiếng anh ---\n",
      "Hello, I'm outdoors. Do you have any outdoor activity suggestions?\n",
      "\n",
      "**Option 1: Hiking**\n",
      "*   **Difficulty:** Easy to Moderate\n",
      "*   **Time:** 2-6 hours\n",
      "*   **Location:** [Insert a local hiking trail or park]\n",
      "*   **Why:** Great exercise, beautiful scenery, and a chance to connect with nature.\n",
      "\n",
      "**Option 2: Bike Ride**\n",
      "*   **Difficulty:** Easy\n",
      "*   **Time:** 1-3 hours\n",
      "*   **Location:** [Insert a local bike path or park]\n",
      "*   **Why:** A fun way to explore your surroundings, get some exercise, and enjoy the fresh air\n",
      "\n",
      "--- Tóm tắt tiếng Việt ---\n",
      "Xin chào, tôi đang ở ngoài trời. Bạn có đề xuất hoạt động ngoài trời nào không?\n",
      "\n",
      "**Lựa chọn 1: Đi bộ đường dài**\n",
      "*   **Độ khó:** Dễ đến Trung bình\n",
      "*   **Thời gian:** 2-6 giờ\n",
      "*   **Địa điểm:** [Chèn một đường mòn đi bộ đường dài hoặc công viên địa phương]\n",
      "*   **Tại sao:** Tập thể dục tuyệt vời, phong cảnh đẹp và cơ hội kết nối với thiên nhiên.\n",
      "\n",
      "**Lựa chọn 2: Đi xe đạp**\n",
      "*   **Độ khó:** Dễ\n",
      "*   **Thời gian:** 1-3 giờ\n",
      "*   **Địa điểm:** [Chèn một đường đi xe đạp hoặc công viên địa phương]\n",
      "*   **Tại sao:** Một cách thú vị để khám phá khu vực xung quanh, tập thể dục và tận hưởng không khí trong lành\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "\n",
    "# def generate(english_text, model, tokenizer, device=\"cuda\"):\n",
    "#     prompt = english_text\n",
    "\n",
    "#     inputs = tokenizer(\n",
    "#         prompt,\n",
    "#         return_tensors=\"pt\",\n",
    "#         truncation=True,\n",
    "#         padding=True,\n",
    "#         max_length=512\n",
    "#     ).to(device)\n",
    "\n",
    "#     model.eval()\n",
    "#     with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "#         outputs = model.generate(\n",
    "#             **inputs,\n",
    "#             max_new_tokens=128,\n",
    "#             do_sample=False,\n",
    "#             num_beams=4,\n",
    "#             early_stopping=True\n",
    "#         )\n",
    "\n",
    "#     summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "#     return summary.strip()\n",
    "\n",
    "# # ==== MAIN INFERENCE ====\n",
    "# # Input: Vietnamese article\n",
    "# vi_text = input(\"User:\\n\")\n",
    "# vi_text = \"\"\"Chào, tôi đang ở ngoài trời. Bạn có gợi ý hoạt động ngoài trời nào không?\"\"\"\n",
    "# gpt_result = \"\"\"\"\"\"\n",
    "\n",
    "# # Step 1: Translate VI -> EN\n",
    "# en_text = translate_vi_to_en(vi_text)\n",
    "\n",
    "# # Step 2: Summarize in EN\n",
    "# summary_en = generate(en_text, model, tokenizer, device=model.device)\n",
    "# # Output\n",
    "# print(\"\\n--- Tóm tắt tiếng anh ---\")\n",
    "# print(summary_en)\n",
    "\n",
    "# # Step 3: Translate back EN -> VI\n",
    "# summary_vi = translate_en_to_vi(summary_en)\n",
    "\n",
    "# # Output\n",
    "# print(\"\\n--- Tóm tắt tiếng Việt ---\")\n",
    "# print(summary_vi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c349ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/hotel/bachn/tmp/ipykernel_3136733/1665329583.py:19: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast():\n",
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tóm tắt tiếng anh ---\n",
      "Hello, I'm outdoors. Do you have any outdoor activity suggestions?\n",
      "\n",
      "I'm looking for something to do that's relatively easy to set up and doesn't require a lot of equipment.\n",
      "\n",
      "Here are some things I've considered:\n",
      "\n",
      "*   **Hiking:**\n",
      "*   **Biking:**\n",
      "*   **Kayaking/Canoeing:**\n",
      "*   **Fishing:**\n",
      "*   **Geocaching:**\n",
      "\n",
      "I'm looking for something that's easy to set up and doesn't require a lot of equipment.\n",
      "\n",
      "Could you suggest something else?\n",
      "\n",
      "**I'm looking for something that's easy to set up and doesn't require a lot\n",
      "\n",
      "--- Tóm tắt tiếng Việt ---\n",
      "Xin chào, tôi đang ở ngoài trời. Bạn có đề xuất hoạt động ngoài trời nào không?\n",
      "\n",
      "Tôi đang tìm kiếm một hoạt động nào đó tương đối dễ thiết lập và không yêu cầu nhiều thiết bị.\n",
      "\n",
      "Dưới đây là một số hoạt động tôi đã xem xét:\n",
      "\n",
      "*   **Đi bộ đường dài:**\n",
      "*   **Đi xe đạp:**\n",
      "*   **Chèo thuyền kayak/chèo thuyền:**\n",
      "*   **Ngư nghiệp:**\n",
      "*   **Tìm kiếm địa lý:**\n",
      "\n",
      "Tôi đang tìm kiếm một hoạt động nào đó dễ thiết lập và không yêu cầu nhiều thiết bị.\n",
      "\n",
      "Bạn có thể đề xuất thêm một hoạt động nào khác không?\n",
      "\n",
      "**Tôi đang tìm kiếm một hoạt động nào đó dễ thiết lập và không yêu cầu nhiều thiết bị.**\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "\n",
    "# # Load model and tokenizer from checkpoint directory\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"./output/checkpoint-200/\").to(\"cuda\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"./output/checkpoint-200/\")\n",
    "\n",
    "# def generate(english_text, model, tokenizer, device=\"cuda\"):\n",
    "#     prompt = english_text\n",
    "\n",
    "#     inputs = tokenizer(\n",
    "#         prompt,\n",
    "#         return_tensors=\"pt\",\n",
    "#         truncation=True,\n",
    "#         padding=True,\n",
    "#         max_length=512\n",
    "#     ).to(device)\n",
    "\n",
    "#     model.eval()\n",
    "#     with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "#         outputs = model.generate(\n",
    "#             **inputs,\n",
    "#             max_new_tokens=128,\n",
    "#             do_sample=False,\n",
    "#             num_beams=4,\n",
    "#             early_stopping=True\n",
    "#         )\n",
    "\n",
    "#     summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "#     return summary.strip()\n",
    "\n",
    "# # ==== MAIN INFERENCE ====\n",
    "# # Input: Vietnamese article\n",
    "# vi_text = input(\"User:\\n\")\n",
    "# vi_text = \"\"\"Chào, tôi đang ở ngoài trời. Bạn có gợi ý hoạt động ngoài trời nào không?\"\"\"\n",
    "# gpt_result = \"\"\"\"\"\"\n",
    "\n",
    "# # Step 1: Translate VI -> EN\n",
    "# en_text = translate_vi_to_en(vi_text)\n",
    "\n",
    "# # Step 2: Summarize in EN\n",
    "# summary_en = generate(en_text, model, tokenizer, device=model.device)\n",
    "# # Output\n",
    "# print(\"\\n--- Tóm tắt tiếng anh ---\")\n",
    "# print(summary_en)\n",
    "\n",
    "# # Step 3: Translate back EN -> VI\n",
    "# summary_vi = translate_en_to_vi(summary_en)\n",
    "\n",
    "# # Output\n",
    "# print(\"\\n--- Tóm tắt tiếng Việt ---\")\n",
    "# print(summary_vi)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
